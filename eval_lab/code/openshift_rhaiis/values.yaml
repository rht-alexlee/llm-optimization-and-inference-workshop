inferenceService:
  storage:
    mode: uri
    storageUri: oci://quay.io/redhat-ai-services/modelcar-catalog:granite-3.3-8b-instruct
  args:
    - "--max-model-len=10000"
    - "--enable-auto-tool-choice"
    - "--tool-call-parser=granite"
    - "--chat-template=/app/data/template/tool_chat_template_granite.jinja"
    - "--deploymentMode=RawDeployment"